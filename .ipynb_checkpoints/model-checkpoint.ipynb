{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-16T21:17:57.834888Z",
     "start_time": "2025-01-16T21:17:56.724430Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from typing import List\n",
    "\n",
    "class RepresentationModuleEncoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 snp_dim: int,\n",
    "                 latent_dim: int,\n",
    "                 hidden_dims: List = None,\n",
    "                 **kwargs) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        modules = []\n",
    "        if hidden_dims is None:\n",
    "            hidden_dims = [32, 64, 128, 256, 512]\n",
    "\n",
    "        in_dim = snp_dim\n",
    "        # Build Encoder\n",
    "        for h_dim in hidden_dims:\n",
    "            modules.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(in_dim, h_dim),\n",
    "                    nn.ELU())\n",
    "            )\n",
    "            in_dim = h_dim\n",
    "\n",
    "        modules.append(nn.Linear(hidden_dims[-1], latent_dim * 2))\n",
    "        self.encoder = nn.Sequential(*modules)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def encode(self, x: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        result = self.encoder(x)\n",
    "\n",
    "        mu = result[:, :self.latent_dim]\n",
    "        log_var = result[:, self.latent_dim:]\n",
    "\n",
    "        return mu, log_var\n",
    "\n",
    "\n",
    "    def reparameterize(self, mu: torch.Tensor, logvar: torch.Tensor) -> torch.Tensor:\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps * std + mu\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor, **kwargs) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        mu, log_var = self.encode(x)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        return mu, log_var, z\n",
    "\n",
    "\n",
    "\n",
    "class RepresentationModuleDecoder(nn.Module):\n",
    "    def __init__(self,snp_dim: int, latent_dim, hidden_dims):\n",
    "        super().__init__()\n",
    "\n",
    "                # Build Decoder\n",
    "        modules = []\n",
    "\n",
    "        if hidden_dims is None:\n",
    "            hidden_dims = [32, 64, 128, 256, 512]\n",
    "\n",
    "        hidden_dims = hidden_dims[::-1]\n",
    "        in_dim = latent_dim\n",
    "        for i in range(len(hidden_dims) - 1):\n",
    "            modules.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(in_dim, hidden_dims[i]),\n",
    "                    nn.ELU())\n",
    "            )\n",
    "            in_dim = hidden_dims[i]\n",
    "\n",
    "        modules.append(nn.Linear(hidden_dims[-1], snp_dim))\n",
    "        self.decoder = nn.Sequential(*modules)\n",
    "\n",
    "    def decode(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Maps the given latent codes\n",
    "        onto the image space.\n",
    "        :param z: (Tensor) [B x D]\n",
    "        :return: (Tensor) [B x C x H x W]\n",
    "        \"\"\"\n",
    "        result = self.decoder_input(z)\n",
    "        result = result.view(-1, 512, 2, 2)\n",
    "        result = self.decoder(result)\n",
    "        return result\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "class AssociationModuleGenerator(nn.Module):\n",
    "    def __init__(self, input_dim: int, generator_hidden_dims: list[int], image_dim: int):\n",
    "        super().__init__()\n",
    "        # AssociationModule is similar to a GAN consisting of a generator and a discriminator\n",
    "        # The generator generates from the latent space consisting of the output from the representation module concatenated with a demographic vector\n",
    "        # It then outputs a fake image vector xmri and an attentive mask a\n",
    "        # the discriminator takes the fake image vector and the real image vector and outputs a probability of the image being real\n",
    "\n",
    "        # The generator is a simple feedforward network with the latent space concatenated with the demographic vector\n",
    "        # The discriminator is a simple feedforward network with the image vector as input\n",
    "\n",
    "        generator_modules = []\n",
    "        if generator_hidden_dims is None:\n",
    "            generator_hidden_dims = [32, 64, 128, 256, 512]\n",
    "\n",
    "        current_dim = input_dim\n",
    "        for h_dim in generator_hidden_dims:\n",
    "            generator_modules.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(current_dim, h_dim),\n",
    "                    nn.ELU())\n",
    "            )\n",
    "            current_dim = h_dim\n",
    "\n",
    "        generator_modules.append(nn.Sequential(nn.Linear(generator_hidden_dims[-1], image_dim * 2), nn.Sigmoid()))\n",
    "\n",
    "        self.generator = nn.Sequential(*generator_modules)\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor, demographic: torch.Tensor, **kwargs) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        # concatenate the demographic vector with the latent space\n",
    "        x = torch.cat([x, demographic], dim=1)\n",
    "        generator_output = self.generator(x)\n",
    "        # split the output into the fake image vector and the attentive mask by splitting the output in half\n",
    "        fake_image = generator_output[:, :generator_output.shape[1] // 2]\n",
    "        attentive_mask = generator_output[:, generator_output.shape[1] // 2:]\n",
    "        return fake_image, attentive_mask\n",
    "\n",
    "class AssociationModuleDiscriminator(nn.Module):\n",
    "    def __init__(self, image_dim: int):\n",
    "        super().__init__()\n",
    "        self.discriminator = nn.Sequential(\n",
    "            nn.Linear(image_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor, **kwargs) -> torch.Tensor:\n",
    "        return self.discriminator(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-16T21:17:57.842364Z",
     "start_time": "2025-01-16T21:17:57.838490Z"
    }
   },
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T21:17:57.888001Z",
     "start_time": "2025-01-16T21:17:57.884880Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DiagnosticianModule (nn.Module):\n",
    "    def __init__(self, input_dim: int, reduction_dim: int, classification_targets: int):\n",
    "        super().__init__()\n",
    "        # perform regression and classification using two linear layers\n",
    "        # after reducing dimensionality to\n",
    "        self.dim_reduction = nn.Sequential(\n",
    "            nn.Linear(input_dim, reduction_dim),\n",
    "            nn.ELU()\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Linear(reduction_dim, classification_targets)\n",
    "        self.regressor = nn.Linear(reduction_dim, 1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, apply_logistic_activation: bool, **kwargs) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        reduced_dims = self.dim_reduction(x)\n",
    "        classification_output = self.classifier(reduced_dims)\n",
    "        regression_output = self.regressor(reduced_dims)\n",
    "        if apply_logistic_activation:\n",
    "            y_hat = nn.functional.softmax(classification_output)\n",
    "            s_hat = nn.functional.sigmoid(regression_output)\n",
    "            return y_hat, s_hat\n",
    "        return classification_output, regression_output"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T21:17:57.933370Z",
     "start_time": "2025-01-16T21:17:57.930145Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GenerativeDiscriminativeModel(nn.Module):\n",
    "    def __init__(self, snp_dims: int, mri_dims: int, demographic_dims, classification_dims: int):\n",
    "        super().__init__()\n",
    "        self.encoder = RepresentationModuleEncoder(snp_dims, 50, [500])\n",
    "        self.decoder = RepresentationModuleDecoder(snp_dims, 50, [500])\n",
    "\n",
    "        self.generator = AssociationModuleGenerator(50 + demographic_dims, [100], mri_dims)\n",
    "        self.discriminator = AssociationModuleDiscriminator(mri_dims)\n",
    "\n",
    "        self.diagnostician = DiagnosticianModule(mri_dims, 25, classification_dims)\n",
    "\n",
    "    def forward(self, snp_features: torch.Tensor, mri_features: torch.Tensor, demographic_features: torch.Tensor):\n",
    "        mu, log_var, z = self.encoder(snp_features)\n",
    "        snp_reconstruction = self.decoder(z)\n",
    "\n",
    "        # concatenate z and demographic features\n",
    "        snp_demographic_features = torch.cat((z, demographic_features), 1)\n",
    "        xmri_fake, attention_mask = self.generator(snp_demographic_features)\n",
    "        xmri_real = mri_features\n",
    "        discriminator_output_fake = self.discriminator(xmri_fake)\n",
    "        discriminator_output_real = self.discriminator(xmri_real)\n",
    "\n",
    "        # hadamard product between the attention mask and the real image\n",
    "        attended_mri_features = attention_mask * xmri_real\n",
    "\n",
    "        y_logits, mmsr_regression = self.diagnostician(attended_mri_features, False)\n",
    "\n",
    "        return snp_reconstruction, mu, log_var, discriminator_output_fake, discriminator_output_real, y_logits, mmsr_regression"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T21:18:50.232455Z",
     "start_time": "2025-01-16T21:18:50.227939Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class AdniDataset(Dataset):\n",
    "    def __init__(self, snp_data: np.ndarray, mri_data: np.ndarray, demographic_data: np.ndarray, diagnosis_data: np.ndarray):\n",
    "        self.raw_snp_data = np.copy(snp_data)\n",
    "        self.mri_data = torch.from_numpy(np.copy(mri_data).astype(np.float32))\n",
    "        self.demographic_data = torch.from_numpy(np.copy(demographic_data).astype(np.float32))\n",
    "        diagnosis_data = np.copy(diagnosis_data)\n",
    "        self.mmse_data = torch.from_numpy(diagnosis_data[:, 1].astype(np.float32))\n",
    "        self.diagnosis_data = torch.from_numpy(diagnosis_data[:, 0].astype(np.int32))\n",
    "        self.snp_data = torch.zeros((self.raw_snp_data.shape[0], self.raw_snp_data.shape[1])).float()\n",
    "\n",
    "\n",
    "    def normalize(self, normalization_matrix: np.ndarray | None = None) -> tuple[np.ndarray, np.ndarray]:\n",
    "        # we have to normalize snp data by computing a normalization matrix. We want as rows all possible values and as columns probability of that value in the dataset\n",
    "        # we then use this matrix to normalize the snp data\n",
    "\n",
    "        # get all unique values in the snp data\n",
    "        if normalization_matrix is None:\n",
    "            unique_values = np.unique(self.raw_snp_data)\n",
    "            normalization_matrix = np.zeros((len(unique_values), self.raw_snp_data.shape[1]))\n",
    "            for i, value in enumerate(unique_values):\n",
    "                normalization_matrix[i] = (self.raw_snp_data == value).sum(axis=0) / self.raw_snp_data.shape[0]\n",
    "\n",
    "        normalized_snp_data = np.zeros((self.raw_snp_data.shape[0], self.raw_snp_data.shape[1]))\n",
    "        # we now have a matrix where each row is a unique value and each column is the probability of that value in the dataset\n",
    "        # we can now normalize the snp data by replacing each value with the corresponding row in the normalization matrix\n",
    "        for i in range(self.raw_snp_data.shape[0]):\n",
    "            for j in range(self.raw_snp_data.shape[1]):\n",
    "                normalized_snp_data[i, j] = normalization_matrix[self.raw_snp_data[i, j], j]\n",
    "\n",
    "        self.snp_data = normalized_snp_data\n",
    "        return normalized_snp_data, normalization_matrix\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.snp_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.snp_data[idx], self.mri_data[idx], self.demographic_data[idx], self.diagnosis_data[idx], self.mmse_data[idx]\n"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T21:18:52.412428Z",
     "start_time": "2025-01-16T21:18:52.409213Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as  np\n",
    "dataset_base_path = \"/media/jfallmann/T9/University/master_thesis/dataset\"\n",
    "\n",
    "mri_raw_path = f\"{dataset_base_path}/mri/raw\"\n",
    "mri_base_path = f\"{dataset_base_path}/mri\"\n",
    "snp_raw_path = f\"{dataset_base_path}/snp/raw\"\n",
    "mri_bids_path = f\"{dataset_base_path}/mri/bids\"\n",
    "mri_fastsurfer_out = f\"{dataset_base_path}/mri/processed\"\n",
    "tables_path = f\"{dataset_base_path}/tables\""
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T21:18:53.802294Z",
     "start_time": "2025-01-16T21:18:53.797880Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import mri data\n",
    "mri_data = np.load(f\"{mri_base_path}/processed_volumes.npy\")\n",
    "# import snp data\n",
    "snp_data = np.load(f\"{dataset_base_path}/snp/processed/genomes.npy\")\n",
    "# import demographic data\n",
    "demographic_data = np.load(f\"{dataset_base_path}/tables/demographic_data.npy\")\n",
    "# import diagnosis data\n",
    "diagnosis_data = np.load(f\"{dataset_base_path}/tables/diagnosis_data.npy\")"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T21:18:54.762077Z",
     "start_time": "2025-01-16T21:18:54.758074Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# get 80/20 train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "snp_train, snp_test, mri_train, mri_test, demographic_train, demographic_test, diagnosis_train, diagnosis_test = train_test_split(snp_data, mri_data, demographic_data, diagnosis_data, test_size=0.2, random_state=42)"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T21:18:56.107426Z",
     "start_time": "2025-01-16T21:18:55.944158Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create dataset\n",
    "train_dataset = AdniDataset(snp_train, mri_train, demographic_train, diagnosis_train)\n",
    "_, normalization_matrix = train_dataset.normalize()\n",
    "\n",
    "test_dataset = AdniDataset(snp_test, mri_test, demographic_test, diagnosis_test)\n",
    "_, _ = test_dataset.normalize(normalization_matrix)"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T21:18:57.606790Z",
     "start_time": "2025-01-16T21:18:57.603977Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T21:17:58.739640502Z",
     "start_time": "2025-01-16T21:08:12.318661Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T21:18:59.164518Z",
     "start_time": "2025-01-16T21:18:59.161133Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def elbo(reconstruction, input, mu, log_var, kld_weight) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    recons_loss =F.mse_loss(reconstruction, input)\n",
    "    kld_loss = torch.mean(-0.5 * torch.sum(1 + log_var - mu ** 2 - log_var.exp(), dim = 1), dim = 0)\n",
    "\n",
    "    loss = recons_loss + kld_weight * kld_loss\n",
    "    return loss,recons_loss.detach(),-kld_loss.detach()"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T21:19:21.544072Z",
     "start_time": "2025-01-16T21:19:21.527893Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, train_loader, optimizer, num_epochs):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    generator_loss_function = nn.MSELoss()\n",
    "    discriminator_loss_function = nn.MSELoss()\n",
    "    classification_loss_function = nn.CrossEntropyLoss()\n",
    "    regression_loss_function = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for snp, mri, demographic, diagnosis, mmse in tqdm(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            snp_reconstruction, mu, log_var, discriminator_output_fake, discriminator_output_real, y_logits, mmsr_regression = model(snp, mri, demographic)\n",
    "\n",
    "            # calculate losses\n",
    "            elbo_loss, recon_loss, kld_loss = elbo(snp_reconstruction, snp, mu, log_var, 0.1)\n",
    "            generator_loss = generator_loss_function(discriminator_output_fake, torch.ones_like(discriminator_output_fake))\n",
    "            discriminator_loss = discriminator_loss_function(discriminator_output_real, torch.ones_like(discriminator_output_real)) + discriminator_loss_function(discriminator_output_fake, torch.zeros_like(discriminator_output_fake))\n",
    "            classification_loss = classification_loss_function(y_logits, diagnosis)\n",
    "            regression_loss = regression_loss_function(mmsr_regression, mmse)\n",
    "\n",
    "            loss = elbo_loss + generator_loss + discriminator_loss + classification_loss + regression_loss\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        train_losses.append(total_loss)\n",
    "        print(f\"Epoch {epoch} loss: {total_loss}. Recon loss: {recon_loss}. KLD loss: {kld_loss}. Generator loss: {generator_loss.item()}. Discriminator loss: {discriminator_loss.item()}. Classification loss: {classification_loss.item()}. Regression loss: {regression_loss.item()}\")\n",
    "    return train_losses"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T21:20:37.918809Z",
     "start_time": "2025-01-16T21:19:51.420315Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create model\n",
    "diagnosis = [1, 3]\n",
    "model = GenerativeDiscriminativeModel(snp_data.shape[1], mri_data.shape[1], demographic_data.shape[1], len(diagnosis))\n",
    "num_epochs = 100\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "train_losses = train(model, train_loader, optimizer, num_epochs)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11 [00:42<?, ?it/s]Exception ignored in: <generator object tqdm.__iter__ at 0x761493dcac20>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jfallmann/miniconda3/envs/mthesis/lib/python3.12/site-packages/tqdm/std.py\", line 1196, in __iter__\n",
      "  File \"/home/jfallmann/miniconda3/envs/mthesis/lib/python3.12/site-packages/tqdm/std.py\", line 1302, in close\n",
      "    self.display(pos=0)\n",
      "  File \"/home/jfallmann/miniconda3/envs/mthesis/lib/python3.12/site-packages/tqdm/std.py\", line 1495, in display\n",
      "  File \"/home/jfallmann/miniconda3/envs/mthesis/lib/python3.12/site-packages/tqdm/std.py\", line 459, in print_status\n",
      "    fp_write('\\r' + s + (' ' * max(last_len[0] - len_s, 0)))\n",
      "  File \"/home/jfallmann/miniconda3/envs/mthesis/lib/python3.12/site-packages/tqdm/std.py\", line 453, in fp_write\n",
      "    fp_flush()\n",
      "  File \"/home/jfallmann/miniconda3/envs/mthesis/lib/python3.12/site-packages/tqdm/utils.py\", line 196, in inner\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jfallmann/miniconda3/envs/mthesis/lib/python3.12/site-packages/ipykernel/iostream.py\", line 609, in flush\n",
      "    if not evt.wait(self.flush_timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jfallmann/miniconda3/envs/mthesis/lib/python3.12/threading.py\", line 655, in wait\n",
      "    signaled = self._cond.wait(timeout)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jfallmann/miniconda3/envs/mthesis/lib/python3.12/threading.py\", line 359, in wait\n",
      "    gotit = waiter.acquire(True, timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[21], line 7\u001B[0m\n\u001B[1;32m      4\u001B[0m num_epochs \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m100\u001B[39m\n\u001B[1;32m      5\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mAdam(model\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1e-3\u001B[39m)\n\u001B[0;32m----> 7\u001B[0m train_losses \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[19], line 14\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(model, train_loader, optimizer, num_epochs)\u001B[0m\n\u001B[1;32m     12\u001B[0m total_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m snp, mri, demographic, diagnosis, mmse \u001B[38;5;129;01min\u001B[39;00m tqdm(train_loader):\n\u001B[0;32m---> 14\u001B[0m     \u001B[43moptimizer\u001B[49m\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m     15\u001B[0m     snp_reconstruction, mu, log_var, discriminator_output_fake, discriminator_output_real, y_logits, mmsr_regression \u001B[38;5;241m=\u001B[39m model(snp, mri, demographic)\n\u001B[1;32m     17\u001B[0m     \u001B[38;5;66;03m# calculate losses\u001B[39;00m\n",
      "File \u001B[0;32m/snap/pycharm-professional/443/plugins/python-ce/helpers/pydev/_pydevd_bundle/pydevd_frame.py:755\u001B[0m, in \u001B[0;36mPyDBFrame.trace_dispatch\u001B[0;34m(self, frame, event, arg)\u001B[0m\n\u001B[1;32m    753\u001B[0m \u001B[38;5;66;03m# if thread has a suspend flag, we suspend with a busy wait\u001B[39;00m\n\u001B[1;32m    754\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m info\u001B[38;5;241m.\u001B[39mpydev_state \u001B[38;5;241m==\u001B[39m STATE_SUSPEND:\n\u001B[0;32m--> 755\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    756\u001B[0m     \u001B[38;5;66;03m# No need to reset frame.f_trace to keep the same trace function.\u001B[39;00m\n\u001B[1;32m    757\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrace_dispatch\n",
      "File \u001B[0;32m/snap/pycharm-professional/443/plugins/python-ce/helpers/pydev/_pydevd_bundle/pydevd_frame.py:412\u001B[0m, in \u001B[0;36mPyDBFrame.do_wait_suspend\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    411\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdo_wait_suspend\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 412\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_args\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/snap/pycharm-professional/443/plugins/python-ce/helpers/pydev/pydevd.py:1220\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[1;32m   1217\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[1;32m   1219\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[0;32m-> 1220\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/snap/pycharm-professional/443/plugins/python-ce/helpers/pydev/pydevd.py:1235\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[1;32m   1232\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[1;32m   1234\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[0;32m-> 1235\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1237\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[1;32m   1239\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 21
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
